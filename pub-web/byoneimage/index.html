<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
    <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MicroDepthComp</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/simonyang.png">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Beyond Single-Image: Achieving Bright-Field Microscopic Image Super
                            Resolution Through Multi-Frame Network from a Single Snapshot</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="">Xinrui Wang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://simonhanyang.github.io/">Han Yang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="">Yufei Jin</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://sse.cuhk.edu.cn/en/faculty/zhangzhuoran">Zhuoran
                                    Zhang</a><sup>*,1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong, Shenzhen</span>
                        </div>
                        

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Data</span>
                                    </a>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="./static/images/ICRA24_3096_GraphicAbstract.jpg" alt="fig1">
                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">Methods for obtaining dense depth maps.</span> Conventionally, depth sensors
                    such as lidars are used to obtain sparse depth, which is then converted into dense depth
                    map via depth completion. However, in micromanipulation setups, depth sensors are unavailable.
                    Traditional methods, such
                    as depth from focus/defocus, yield depth maps with poor resolution. Our approach employs contact
                    detection within a
                    robotic micromanipulation system, coupled with deep learning methods, to generate dense depth maps.
                </h2>
            </div>
        </div>
    </section> -->


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <img src="./static/images/bysi-fig-one.png" alt="" height="30%">

                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">The results obtained with super-resolution using a
                        single image input have insufficient detail, which is recovï¿¾ered after the SIMFA-SR paradigm.
                </h2>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            In bright-field microscopy, a trade-off exists between magnification and field of view, where low magnification captures overall structures but lacks details, 
                            while high magnification reveals high-resolution features but limits the observable area. To address this, image super-resolution (SR) utilizing deep learning can predict 
                            and enhance missing details. However, single-image super-resolution (SISR) struggles with limited input information due to camera resolution constraints, particularly in 
                            bright-field microscopy. Multi-frame super-resolution (MFSR) methods leverage sub-pixel displacements caused by hand tremors during image acquisition, thus integrating spatial 
                            information from consecutive images to improve detail recovery. Unfortunately, it is challenging to acquire such image sequences under microscopes.
                        </p>
                        <p>
                            This work proposes a novel paradigm, Single-Image Multi-Frame Augmentation Super-Resolution (SIMFA-SR), 
                            which takes a single image as input and generates multi-frame variants to simulate MFSR benefits without additional equipment. 
                            A Refine-Perception Multivariant Image Network (RP-MIN) was developed to effectively integrate multi-frame features and produce coherent super-resolution images, 
                            thereby enhancing the analysis of biological samples while maintaining imaging convenience.
                        </p>
                        <p>
                            In addition to evaluating the network on existing datasets with limited image pairs, a dataset containing 71900 images covering 10x, 20x, and 40x magnifications was created. 
                            The experimental results showed that the proposed method achieved a improvement of 2.77 dB in PSNR compared to traditional SISR techniques.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">RP-MIN</h2>
                    <img src="./static/images/bysi-net.png" alt="">

                    <!-- <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div> -->
                </div>
            </div>
            <!--/ Paper video. -->
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Experimental Results</h2>

                    <!-- Interpolating. -->
                    <h3 class="title is-4">Qualitative Super Resolution Results</h3>
                    {% comment %} <div class="content has-text-justified">
                        <p>
                            <span class="dnerf">Qualitative depth completion results by the proposed method.</span>The original images of Hela cells and the corresponding depth map are shown in parallel.

                        </p>
                    </div> {% endcomment %}
                    <div class="columns is-vcentered interpolation-panel">
                        <img src="./static/images/res.png" class="interpolation-image" alt="Interpolate start reference image." />                        
                    </div>
                    <br />
                    <!--/ Interpolating. -->
                </div>
            </div>
            <!--/ Animation. -->
        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{xinrui2024beyond,
author    = {Xinrui Wang, Han Yang, Yufei Jin, Zhuoran Zhang},
title     = {Beyond Single-Image: Achieving Bright-Field Microscopic Image Super Resolution through Multi-Frame Network from a Single Snapshot.},
journal   = {AAAI},
year      = {2025},
}
                </code>
            </pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/SimonHanYANG" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This website is ref by <a rel="license" href="https://nerfies.github.io/">Nerfies Website</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/SimonHanYANG">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>