<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
    <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MicroDepthComp</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/simonyang.png">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Weakly-Supervised Depth Completion during Robotic
                            Micromanipulation from a Monocular Microscopic Image</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://simonhanyang.github.io/">Han Yang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="">Yufei Jin</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="">Guanqiao Shan</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="">Yibin Wang</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="">Yongbin Zheng</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.imlyu.com/team">Jiangfan Yu</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://amnl.mie.utoronto.ca/">Yu Sun</a><sup>*,2</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://sse.cuhk.edu.cn/en/faculty/zhangzhuoran">Zhuoran
                                    Zhang</a><sup>*,1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong, Shenzhen</span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>2</sup>University of Toronto</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Data</span>
                                    </a>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="./static/images/paper1-fig1-2.png" alt="fig1">
                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">Methods for obtaining dense depth maps.</span> Conventionally, depth sensors
                    such as lidars are used to obtain sparse depth, which is then converted into dense depth
                    map via depth completion. However, in micromanipulation setups, depth sensors are unavailable.
                    Traditional methods, such
                    as depth from focus/defocus, yield depth maps with poor resolution. Our approach employs contact
                    detection within a
                    robotic micromanipulation system, coupled with deep learning methods, to generate dense depth maps.
                </h2>
            </div>
        </div>
    </section>


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <img src="./static/images/paper1_flow_chart.png" alt="" height="100%">

                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">Pipepine for depth completion during robotic micromanipulation.</span> The
                    pipeline first plans regions for contact detection, then in each region automated contact detection
                    is performed
                    only once to avoid repeated experiments on regions with similar image features. The collected sparse
                    depth data are then
                    augmented and fed into a depth completion network, followed by a refinement process to generate a
                    dense depth map.
                </h2>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Obtaining three-dimensional information, especially the z-axis depth information, is crucial
                            for robotic
                            micromanipulation. Due to the unavailability of depth sensors such as lidars in
                            micromanipulation setups, traditional
                            depth acquisition methods such as depth from focus or depth from defocus directly infer
                            depth from microscopic images
                            and suffer from poor resolution. Alternatively, micromanipulation tasks obtain accurate
                            depth information by detecting
                            the contact between an end-effector and an object (e.g., a cell). Despite its high accuracy,
                            only sparse depth data can
                            be obtained due to its low efficiency.
                        </p>
                        <p>
                            This paper aims to address the challenge of acquiring dense depth information
                            during robotic cell micromanipulation. A weakly-supervised depth completion network is
                            proposed to take cell images and
                            sparse depth data obtained by contact detection as input to generate a dense depth map. A
                            two-stage data augmentation
                            method is proposed to augment the sparse depth data, and the depth map is optimized by a
                            network refinement method.
                        </p>
                        <p>
                            The experimental results show that the MAE value of the depth prediction error is less than
                            0.3 mu m, which proves the
                            accuracy and effectiveness of the method. This deep learning network pipeline can be
                            seamlessly integrated with the
                            robotic micromanipulation tasks to provide accurate depth information.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <img src="./static/images/paper1-video.png" alt="">

                    <!-- <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div> -->
                </div>
            </div>
            <!--/ Paper video. -->
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Experimental Results</h2>

                    <!-- Interpolating. -->
                    <h3 class="title is-4">Qualitative Depth Completion Results</h3>
                    <div class="content has-text-justified">
                        <p>
                            <span class="dnerf">Qualitative depth completion results by the proposed method.</span>The original images of Hela cells and the corresponding depth map are shown in parallel.

                        </p>
                    </div>
                    <div class="columns is-vcentered interpolation-panel">
                        <img src="./static/images/result.png" class="interpolation-image" alt="Interpolate start reference image." />                        
                    </div>
                    <br />
                    <!--/ Interpolating. -->
                </div>
            </div>
            <!--/ Animation. -->
        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{han2024weekly,
author    = {Han Yang, Yufei Jin, Guanqian Shan, Yibin Wang, Yongbin Zheng, Jiangfan Yu, Yu Sun, Zhuoran Zhang},
title     = {Weakly-Supervised Depth Completion during Robotic Micromanipulation from a Monocular Microscopic Image},
journal   = {ICRA},
year      = {2024},
}
                </code>
            </pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/SimonHanYANG" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This website is ref by <a rel="license" href="https://nerfies.github.io/">Nerfies Website</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/SimonHanYANG">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>